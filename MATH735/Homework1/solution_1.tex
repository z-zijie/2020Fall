\documentclass{article}
% --- Modify margins --- %
\usepackage{geometry}
\geometry{a4paper,scale=0.8}
% --- Involved packages --- %
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{enumerate}

% --- Title information --- %
\title{Math 735 - Fall 2020\\
        {\Large \textbf{Homework 1}}\\
        {\normalsize \textbf{Due: 10/14}}
    }
\author{Zijie Zhang}
\date{\today}


% --- main --- %

\begin{document}
    \maketitle
% --- Question 1 --- %
\section*{Question 1}
    \begin{proof}
        If $Y$ has a single continuous path, then it means there exists a $\omega$ s.t. $Y_t(\omega)=0$ for all $t$. This is equivalent to
        $$\exists\  \omega \in [0,1] \text{ s.t. } t \not= \omega \ \forall t\in \mathbb{R}_{+}$$
        This is impossible, so $Y$ does not have a single continuous path.\\
        $X$ and $Y$ are modifications of each other means
        $$\mathbb{P}(X_t=Y_t)=\mathbb{P}(Y_t=0)=\mathbb{P}(t \not= \omega)=1$$
        For any fixed $\omega$, this is true. So, $X$ and $Y$ are modifications of each other.
    \end{proof}

% --- Question 2 --- %
\section*{Question 2}
    \begin{proof}
    We need prove $\widetilde{B_t}$ is a Gaussian process.
    $$\widetilde{\mathbb{P}}(t,x)=\mathbb{P}(\lambda^2 t, \lambda x)=\frac{1}{\sqrt{2\pi \lambda^2 t}}e^{-\frac{(\lambda x)^2}{2\lambda^2 t}}=\frac{1}{\lambda}\cdot\frac{1}{\sqrt{2\pi t}}e^{-\frac{x^2}{2t}}=\frac{1}{\lambda}\mathbb{P}(t,x)$$
    So, $\widetilde{B_t}\sim \frac{1}{\lambda}N(0,t)=N(0,\frac{t}{\lambda^2})$
    \end{proof}

% --- Question 3 --- %
\section*{Question 3}
    \begin{proof}
    \begin{align*}
        E[B_t^k] &=\int_{-\infty}^{\infty} x^k \frac{1}{\sqrt{2\pi t}}e^{-\frac{x^2}{2t}}dx\\
        &=\left.\frac{1}{k+1}x^{k+1}\cdot\frac{1}{\sqrt{2\pi t}}e^{-\frac{x^2}{2t}}\right|_{-\infty}^{\infty}+\frac{1}{t(k+1)}\int_{-\infty}^{\infty}x^{k+2}\frac{1}{\sqrt{2\pi t}}e^{-\frac{x^2}{2t}}dx\\
        &=\frac{1}{t(k+1)}E[B_t^{k+2}]
    \end{align*}
    $$E[B_t^{k+2}]=t(k+1)E[B_t^k]$$
    We know $E[B_t^0]=1$, $E[B_t^1]=0$, so we have\\
    When $k=2j$,
    $$E[B_t^k]=t^j\prod_{i=1}^j(2i-1)$$
    When $k=2j-1$
    $$E[B_t^k]=0$$
    \end{proof}

% --- Question 4 --- %
\section*{Question 4}
    \begin{proof}
        \indent
        \textit{Stopping time}
        \begin{enumerate}
            \item Play until there is no money or play 500 games before stopping.
            \item Play N games to stop,$\{\tau=N\}$
            \item Flip a coin N times, stop at the first appearance of \textit{head, tail, head}.
        \end{enumerate}
        \textit{Not stopping time}
        \begin{enumerate}
            \item Stopping gambling when the gambler gets the maximum amount of money he can win is not a stopping time.\\
            \textit{Explanation:} Because it needs not only the information of the present and the past, but also the information of the future.
            \item Stopping when the gambler doubles his wager is not a stopping time.\\
            \textit{Explanation:} Because there is a positive probability that he will never double his money.
            \item Sold the day before the stock fell is not a stopping time.\\
            \textit{Explanation:} Because we donâ€™t know the future information.
        \end{enumerate}
    \end{proof}

% --- Question 5 --- %
\section*{Question 5}
    
    \textit{($L^p$ martingale convergence for $p>1$ in discrete time)}\\
    Show that if $\{M_n\}$ is a martingale that satisfies
    $$\mathbb{E}\left[\left|M_n\right|^p\right] \leqslant B < \infty$$
    for some $p>1$ and for all $n\geqslant 0$, then there exists a random variable $M_\infty$ with $\mathbb{E}\left[\left| M_\infty\right|^p\right]\leqslant B$ such that
    $$\mathbb{P}\left(\lim_{n\to \infty}M_n = M_\infty\right)=1 \text{ and } \lim_{n\to \infty}||M_n-M_\infty||_p=0$$
    \begin{proof}
    By Jensen's inequality,
    $$f(x)=x^p \text{ is a convex function for } p>1$$
    It gives $f(\mathbb{E}[|M_n|])\leqslant \mathbb{E}[f(|M_n|)] \Rightarrow \mathbb{E}[|M_n|]^p \leqslant \mathbb{E}[|M_n|^p]\leqslant B <\infty$.\\
    By $L^1$ martingale convergence Theorem, there exists $M_\infty$ bounded such that
    $$\mathbb{P}\left(\lim_{n\to \infty}M_n = M_\infty\right)=1 \text{ and } \lim_{n\to \infty}||M_n-M_\infty||_p=0$$
    By fatou's Lemma,$\mathbb{E}[|M_\infty|^p]$ is bounded, because
    $$\mathbb{E}[|M_\infty|^p]=\mathbb{E}[\lim_{n\to\infty}|M_n|^p]\leqslant \liminf_{n\to \infty}\mathbb{E}[|M_n|^p]\leqslant B<\infty$$
    By Doob's $L^p$ maximal inequality, it gives
    $$\mathbb{E}[|M_n^*|^p]^{\frac{1}{p}}\leqslant \frac{p}{1-p}\mathbb{E}[|M_n|^p]^{\frac{1}{p}}\leqslant\frac{p}{p-1}B^{\frac{1}{p}}<\infty$$
    Then $\mathbb{E}[|M_n^*|^p]^{\frac{1}{p}} \to \text{a finite number}$.
    Let $$\lim_{n\to \infty}||M_n^*||_p =||M_\infty^*||_p<\infty$$
    Thus,
    $$\lim_{n\to\infty} ||M_n-M_\infty||_p=||\lim_{n\to\infty}M_n - M_\infty||_p=0$$
    \end{proof}

% --- Question 6 --- %
\section*{Question 6}
    \begin{proof}
    Assume that $M_t$ is a submartingale.
    By Theorem 3.6, we know
    $$\mathbb{E}[M_{\tau \wedge T|\mathcal{F}_s}]\geqslant M_{\tau\wedge T \wedge s}$$
    We know $M_{\tau\wedge T \wedge s}=M_{\tau \wedge s}$, since $s<T$. Thus
    $$\mathbb{E}[M_{\tau \wedge T|\mathcal{F}_s}]\geqslant M_{\tau \wedge s}$$
    Hence, $M_{\tau \wedge s}$ is also a submartingale. In Ex3.2, we know $B$ is a standard Brownian motion and $\tau=\inf{t\geqslant 0: B_t=1}$. By Stopping Time Theorem, we have $\mathbb{E}[B_{\tau\wedge t}]=\mathbb{E}[B_0]=0$.\\
    However,
    $$\mathbb{E}[B_\tau]=-P(B_\tau=-1)=-1 \not=0$$
    So, Theorem3.6 cannot hold without the truncation by T.
    \end{proof}

% --- Question 7 --- %
\section*{Question 7}
    \begin{proof}
    Consider the \textit{1D-symmetric random walk} with
    $$\forall i\in \mathbb{N},\ P(X_i = 1) = P(X_i = -1) = \frac{1}{2}$$
    Set $$S_n = \sum_{i=1}^n X_k$$the sum of first n-th terms of $X_i$, it is a martingale.\\
    Let $\sigma$ be the time arrive position $Y$, and let $\tau=\sigma+1$. Here $\sigma$ is a stopping time.\\
    If $\tau$ is also a stopping time,
    $$\mathbb{E}[S_\tau|\mathcal{F}_\sigma]=S_\sigma$$
    Then, we have
    $$\mathbb{E}[S_\tau]=\mathbb{E}[S_\sigma]=\mathbb{E}[S_{\sigma-1}]=\cdots=0$$
    However,
    $$\mathbb{E}[S_\tau]=Y\not=0$$

    
    \end{proof}
\end{document}