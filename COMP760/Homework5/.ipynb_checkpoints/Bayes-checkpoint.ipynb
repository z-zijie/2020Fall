{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = np.delete(np.genfromtxt('titanic_data.csv', delimiter=','), 0, 0)\n",
    "X = data[:,1:]\n",
    "y_label = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gaussian(val, mean, var):\n",
    "    ans = math.exp(-(val-mean)*(val-mean)/(2*var))\n",
    "    ans = ans/math.sqrt(2*math.pi*var)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(dataset, label):\n",
    "    index_survived = np.where(label==1)[0]\n",
    "    index_not_survived = np.where(label==0)[0]\n",
    "    p_survived = len(index_survived) / len(label)\n",
    "    \n",
    "    \n",
    "    # BernoulliNB\n",
    "    Bernoulli_feature = [0, 1, 3, 4]\n",
    "    p_estimate_0 = [] # NOT survived\n",
    "    p_estimate_1 = [] # survived\n",
    "    for feature in Bernoulli_feature:\n",
    "        p_feature_0 = []\n",
    "        p_feature_1 = []\n",
    "        value = np.unique(dataset[:,feature])\n",
    "        K = len(value)\n",
    "        for val in value:\n",
    "            p_feature_0.append(len(1+np.where((dataset[:, feature]==val) & (label==0))[0])/ (K+len(index_not_survived)))\n",
    "            p_feature_1.append(len(1+np.where((dataset[:, feature]==val) & (label==1))[0])/ (K+len(index_survived)))\n",
    "        p_estimate_0.append(p_feature_0)\n",
    "        p_estimate_1.append(p_feature_1)\n",
    "    \n",
    "    # GaussianNB\n",
    "    Gaussian_feature = [2, 5]\n",
    "    Gaussian_parameter_0 = []\n",
    "    Gaussian_parameter_1 = []\n",
    "    dataset_0 = dataset[index_not_survived]\n",
    "    dataset_1 = dataset[index_survived]\n",
    "    \n",
    "    for feature in Gaussian_feature:\n",
    "        Gaussian_parameter_0.append([np.mean(dataset_0[:, feature]), np.var(dataset_0[:, feature])])\n",
    "        Gaussian_parameter_1.append([np.mean(dataset_1[:, feature]), np.var(dataset_1[:, feature])])\n",
    "    \n",
    "    return p_estimate_0, p_estimate_1, Gaussian_parameter_0, Gaussian_parameter_1, p_survived, dataset, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNB(x, estimate):\n",
    "    dataset = estimate[5]\n",
    "    label = estimate[6]\n",
    "    Bernoulli_feature = [0, 1, 3, 4]\n",
    "    Gaussian_feature = [2, 5]\n",
    "    \n",
    "    # survived\n",
    "    p = estimate[4]\n",
    "    p_estimate_1 = estimate[1]\n",
    "    Gaussian_parameter_1 = estimate[3]\n",
    "    \n",
    "    for i in range(len(Bernoulli_feature)):\n",
    "        feature = Bernoulli_feature[i]\n",
    "        unique_feature = np.unique(dataset[:,feature]).tolist()\n",
    "        if x[feature] in unique_feature:\n",
    "            j = unique_feature.index(x[feature])\n",
    "        else:\n",
    "            j = len(unique_feature)-1\n",
    "#         j = np.where(np.unique(dataset[:,feature]) == x[feature])[0][0]\n",
    "        p = p * p_estimate_1[i][j]\n",
    "    for i in range(len(Gaussian_feature)):\n",
    "        feature = Gaussian_feature[i]\n",
    "        Mean = Gaussian_parameter_1[i][0]\n",
    "        Var = Gaussian_parameter_1[i][1]\n",
    "        p = p * gaussian(x[feature], Mean, Var)\n",
    "    p_survived = p\n",
    "    \n",
    "    # NOT survived\n",
    "    p = 1 - estimate[4]\n",
    "    p_estimate_0 = estimate[0]\n",
    "    Gaussian_parameter_0 = estimate[2]\n",
    "    \n",
    "    for i in range(len(Bernoulli_feature)):\n",
    "        feature = Bernoulli_feature[i]\n",
    "        unique_feature = np.unique(dataset[:,feature]).tolist()\n",
    "        if x[feature] in unique_feature:\n",
    "            j = unique_feature.index(x[feature])\n",
    "        else:\n",
    "            j = len(unique_feature)-1\n",
    "#         j = np.where(np.unique(dataset[:,feature]) == x[feature])[0][0]\n",
    "        p = p * p_estimate_0[i][j]\n",
    "    for i in range(len(Gaussian_feature)):\n",
    "        feature = Gaussian_feature[i]\n",
    "        Mean = Gaussian_parameter_0[i][0]\n",
    "        Var = Gaussian_parameter_0[i][1]\n",
    "        p = p * gaussian(x[feature], Mean, Var)\n",
    "    p_not_survived = p\n",
    "    if p_survived > p_not_survived:\n",
    "        return 1\n",
    "    return 0\n",
    "# estimate = fit(X, y_label)\n",
    "# predictNB(X[1], estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7733934611048479\n"
     ]
    }
   ],
   "source": [
    "# KFold\n",
    "from sklearn.model_selection import KFold\n",
    "ans = np.zeros(len(X))\n",
    "kf = KFold(n_splits = 10, shuffle = True)\n",
    "kf.get_n_splits(X)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_label[train_index], y_label[test_index]\n",
    "\n",
    "    estimate = fit(X_train, y_train)\n",
    "    for i in range(len(test_index)):\n",
    "        ans[test_index[i]] = (predictNB(X_test[i], estimate) == y_test[i])\n",
    "accuracy = sum(ans)/len(ans)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# personal data\n",
    "estimate = fit(X, y_label)\n",
    "x = np.array([1, 1, 22, 1, 0, 71.2833])\n",
    "print(predictNB(x, estimate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X, y_label)\n",
    "print(clf.predict([X[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, y_label)\n",
    "print(clf.predict([X[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y_label)\n",
    "print(clf.predict([X[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857948139797069\n"
     ]
    }
   ],
   "source": [
    "# KFold\n",
    "ans = np.zeros(len(X))\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 10, shuffle = True)\n",
    "kf.get_n_splits(X)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_label[train_index], y_label[test_index]\n",
    "    clf = BernoulliNB()\n",
    "#     clf = GaussianNB()\n",
    "#     clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    for i in range(len(test_index)):\n",
    "        ans[test_index[i]] = (clf.predict([X_test[i]]) == y_test[i])\n",
    "accuracy = sum(ans)/len(ans)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_survived = np.where(y_label==1)\n",
    "index_not_survived = np.where(y_label==0)\n",
    "p_survived = len(index_survived) / len(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gaussian(val, mean, var):\n",
    "    ans = math.exp(-(val-mean)*(val-mean)/(2*var))\n",
    "    ans = ans/math.sqrt(2*math.pi*var)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "print(math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0.])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
