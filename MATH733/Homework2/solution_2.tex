\documentclass{article}
% --- Modify margins --- %
\usepackage{geometry}
\geometry{a4paper,scale=0.8}
% --- Involved packages --- %
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{bbm}

% --- Title information --- %
\title{Math 733 - Fall 2020\\
        {\Large \textbf{Homework 2}}\\
        {\normalsize \textbf{Due: 09/27, 10pm}}
    }
\author{Zijie Zhang}
\date{\today}


% --- main --- %

\begin{document}
    \maketitle
    \begin{enumerate}
        % === Question 1 ===
        \item \begin{proof}
            $\Rightarrow$ $Y$ is measurable w.r.t. $\sigma(X)$
            \begin{itemize}
                \item $Y=\mathbbm{1}_{X^{-1}(B)}$ for some Borel set $B$ and $f(X)=\mathbbm{1}_{B}(X)$ then $Y(\omega)=\mathbbm{1}_{B}(X(\omega))=f(X(\omega))$.
                \item $Y=\sum_{i=1}^{n}c_i\mathbbm{1}_{X^{-1}(B_i)}(\omega)$ for some Borel sets $B_i$ and $f(x)=\sum_{i=1}^n c_1 \mathbbm{1}_{B_i}(X)$ then
                $$Y(\omega)=\sum_{i=1}^{n}c_i\mathbbm{1}_{X^{-1}(B_i)}(\omega)=\sum_{i=1}^{n} c_i \mathbbm{1}_{B_i}(X(\omega))=f(X(\omega))$$
                \item Sequential random variables $Y_n$, $\lim_{n\to \infty}Y_n=Y$ and $f_n$. Set $f(X)=\limsup{f_n(X)}$,
                $$f(X(\omega))=\limsup{f_n(X(\omega))}=\lim_{n \to \infty}Y_n(\omega)=Y(\omega)$$
            \end{itemize}
            So, $Y=f(X)$ where $f:\mathbb{R}\to \mathbb{R}$ is measurable.

            $\Leftarrow$ Assume $Y=f(X)$ where $f:\mathbb{R}\to \mathbb{R}$ is measurable.\\
            Since $X$ is a random variable on $(\Omega,\mathscr{F},\mathbb{P})$, then
            $X:\Omega \to \mathbb{R}$ and $X^{-1}(B)\subseteq \mathscr{F}$ where $B$ is any Borel set.\\
            $\sigma(X)$ is the $\sigma$-field generated by $X^{-1}(B)$. We know, $Y=f(X):\Omega \to \mathbb{R}$ and $(f\circ X)^{-1}(B)=X^{-1}\circ f^{-1}(B)$.\\
            Since $f$ is measurable, so $f^{-1}(B)$ is also a Borel set.
            So, $Y=f(X)$ is measurable w.r.t $\sigma(X)$.\\


            Assume $X$ and $Y$ are random variables from $\left(\Omega, \mathcal{F}\right)$
            to $(S,\mathcal{S})$, then
            $$\{\omega:f\left(X(\omega)\right)\in B\}
            =\{\omega:X(\omega) \in f^{-1}(B)\}
            \in \mathcal{F}$$
            If and only if $f^{-1}(B) \in \sigma(X)$,
            $Y = f(X)$ is measurable w.r.t $\sigma(X)$.
        \end{proof}

        % === Question 2 ===
        \item \begin{proof}
            $$\lim_{p\to\infty}E\left(X^p\right)=\lim_{p\to\infty}{\lim_{n\to\infty}\sum_{i=1}^n \left(\frac{i}{n}\right)^p \mathbb{P}\left(X=\frac{i}{n}\right)}$$
            We have
            \begin{align*}
                E\left(X^p\right)
                &=\lim_{n\to\infty}\sum_{i=1}^n \left(\lim_{p\to\infty}\left(\frac{i}{n}\right)^p\mathbb{P}\left(X=\frac{i}{n}\right)\right)\\
                &=\lim_{n\to \infty}\left(0+\left(\frac{i}{n}\right)^p \left .\mathbb{P}\left(X=\frac{i}{n}\right)\right|_{i=n}\right)\\
                &=\mathbb{P}\left(X=1\right)
            \end{align*}
            So, $E\left(X^p\right)=\mathbb{P}\left(X=1\right)$ as $p\to \infty$.
        \end{proof}

\pagebreak

        % === Question 3 ===
        \item \begin{proof}
            \indent
            \begin{itemize}
                \item[(a)]
                    Consider \textit{Derangement formula}
                    $$\mathbb{P}(X_n=0)=\frac{D(n)}{n!}$$
                    where $$D(n)=n!\cdot \sum_{k=2}^{n}\frac{(-1)^k}{k!}$$
                    Then $$\mathbb{P}(X_n=0)=\sum_{k=2}^{n}\frac{(-1)^k}{k!}$$
                    When $n\to \infty$,
                    $$\mathbb{P}(X_n=0)\to\sum_{k=2}^{\infty}\frac{(-1)^k}{k!}$$
                    This is one of the expression of $\frac{1}{e}$.
                    $$\lim_{n\to\infty} \mathbb{P}(X_n=0)=\frac{1}{e}$$
                \item[(b)]
                    Noticed that
                    $$\mathbb{P}(X_n=1) = \frac{{n \choose 1}D(n-1)}{n!}=\frac{D(n-1)}{(n-1)!}=\mathbb{P}(X_{n-1}=0)$$
                    $$\mathbb{P}(X_n=2) = \frac{{n \choose 2}D(n-2)}{n!}=\frac{1}{2}\cdot\frac{D(n-2)}{(n-2)!}=\frac{1}{2}\mathbb{P}(X_{n}=0)$$
                    $$\mathbb{P}(X_n=k) = \frac{{n \choose k}D(n-k)}{n!}=\frac{1}{k}\mathbb{P}(X_n=k-1)$$
                    So, we have
                    $$\mathbb{P}(X_n=k)=\frac{1}{k!}\cdot \mathbb{P}(X_n=0)$$
                    \begin{align*}
                        E[X_n]&=\sum_{k=0}^n k\cdot \mathbb{P}(X_n=k)\\
                        &=\sum_{k=0}^n k\cdot \frac{1}{k!}\mathbb{P}(X_n=0)\\
                        &=\mathbb{P}(X_n=0)\cdot\sum_{k=1}^n \frac{1}{(k-1)!}\\
                        &=\sum_{k=2}^n \frac{(-1)^k}{k!}\cdot \sum_{k=1}^n\frac{1}{(k-1)!}
                    \end{align*}
                    By the way, when $n$ is large enough, $E[X_n] \to 1$.
            \end{itemize}
        \end{proof}
\pagebreak
        % === Question 4 ===
        \item \begin{proof}
            $$E[Y]=\int_\Omega y\cdot\mathbbm{1}(Y>0) d\mathbb{P}$$
            $$E[Y^2]=\int_\Omega y^2 d\mathbb{P}$$
            Consider the Integral form of \textit{Cauchyâ€“Schwarz inequality}.
            \begin{align*}
                \left(E[Y]\right)^2
                &=\left(\int_\Omega y\cdot\mathbbm{1}(y>0) d\mathbb{P}\right)^2\\
                &\leqslant \int_\Omega \left(y\cdot\sqrt{\mathbbm{1}(y>0)}\right)^2 d\mathbb{P}\cdot \int_\Omega \left(\sqrt{\mathbbm{1}(y>0)}\right)^2 d\mathbb{P}\\
                &\leqslant\mathbb{P}(Y>0)\cdot E[Y^2]
            \end{align*}
            $$\mathbb{P}(Y>0) \geqslant \frac{\left(E[Y]\right)^2}{E[Y^2]}$$
        \end{proof}

        % === Question 5 ===
        \item \begin{proof}
            $\Leftarrow$ Assume that
            $$g_j(x)=\sum_{i\in S}\mathbb{P}(X_j=x_j)\mathbbm{1}_{\{x_j\}}(x)\geqslant 0$$
            So we have
            $$\mathbb{P}(X_1=x_1,\cdots,X_n=x_n)=\prod_{j=1}^n g_j(x_j)=\prod_{j=1}^n\mathbb{P}(X_j=x_j)=\mathbb{P}(X_1=x_1)\cdots\mathbb{P}(X_n=x_n)$$
            By definition, they are independent.

            $\Rightarrow$ If they are independent, we have
            $$\mathbb{P}\left(X_1=x_1, \cdots, X_n=x_n\right)
            =\prod_{j=1}^n \mathbb{P}\left(X_j=x_j\right)$$
            Let $g_j(x) = \mathbb{P}\left(X_j=x\right)$ for all $1\leqslant j \leqslant n$, they are non-negative functions from $S$ to $\mathbb{R}$.
        \end{proof}

        % === Question 6 ===
        \item \begin{proof}
            Consider the expression of $\omega$ in binary. The probability of $X_n=1$
            means the probability that the $n$th decimal place is 1.
            By the definition and arbitrariness of $\omega$, we know
            $$\mathbb{P}\left(X_n=0\right)=\mathbb{P}\left(X_n=1\right)=\frac{1}{2}$$
            That means, $$X_n \sim \text{Bernoulli(1/2)}, \ \forall n\in \mathbb{N}$$
            And their independence is obvious.
        \end{proof}
    
    \end{enumerate}
\end{document}