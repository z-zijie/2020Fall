{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         Survived      Pclass         Sex         Age  \\\ncount  887.000000  887.000000  887.000000  887.000000   \nmean     0.385569    2.305524    0.354002   29.471443   \nstd      0.487004    0.836662    0.478480   14.121908   \nmin      0.000000    1.000000    0.000000    0.420000   \n25%      0.000000    2.000000    0.000000   20.250000   \n50%      0.000000    3.000000    0.000000   28.000000   \n75%      1.000000    3.000000    1.000000   38.000000   \nmax      1.000000    3.000000    1.000000   80.000000   \n\n       Siblings/Spouses Aboard  Parents/Children Aboard       Fare  \ncount               887.000000               887.000000  887.00000  \nmean                  0.525366                 0.383315   32.30542  \nstd                   1.104669                 0.807466   49.78204  \nmin                   0.000000                 0.000000    0.00000  \n25%                   0.000000                 0.000000    7.92500  \n50%                   0.000000                 0.000000   14.45420  \n75%                   1.000000                 0.000000   31.13750  \nmax                   8.000000                 6.000000  512.32920  \n- - - - - - - - - - - - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('titanic_data.csv')\n",
    "print(data.describe())\n",
    "print('- - - - - - - - - - - - - - - - - - - -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First, I divided these six features into two categories.\nCATEGORICAL_FEATURES and NUMERICAL_FEATURES\nFor CATEGORICAL_FEATURES, I directly convert it to one-hot encoding.\nFor NUMERICAL_FEATURES, binning the data and then convert it to one-hot encoding.\n       Survived_0  Survived_1    Pclass_1    Pclass_2    Pclass_3       Sex_0  \\\ncount  887.000000  887.000000  887.000000  887.000000  887.000000  887.000000   \nmean     0.614431    0.385569    0.243517    0.207441    0.549042    0.645998   \nstd      0.487004    0.487004    0.429447    0.405703    0.497870    0.478480   \nmin      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n50%      1.000000    0.000000    0.000000    0.000000    1.000000    1.000000   \n75%      1.000000    1.000000    0.000000    0.000000    1.000000    1.000000   \nmax      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n\n            Sex_1  Siblings/Spouses Aboard_0  Siblings/Spouses Aboard_1  \\\ncount  887.000000                 887.000000                 887.000000   \nmean     0.354002                   0.680947                   0.235626   \nstd      0.478480                   0.466373                   0.424629   \nmin      0.000000                   0.000000                   0.000000   \n25%      0.000000                   0.000000                   0.000000   \n50%      0.000000                   1.000000                   0.000000   \n75%      1.000000                   1.000000                   0.000000   \nmax      1.000000                   1.000000                   1.000000   \n\n       Siblings/Spouses Aboard_2  ...  Age_(0.419, 19.0]  Age_(19.0, 24.0]  \\\ncount                 887.000000  ...         887.000000        887.000000   \nmean                    0.031567  ...           0.224352          0.177001   \nstd                     0.174943  ...           0.417390          0.381885   \nmin                     0.000000  ...           0.000000          0.000000   \n25%                     0.000000  ...           0.000000          0.000000   \n50%                     0.000000  ...           0.000000          0.000000   \n75%                     0.000000  ...           0.000000          0.000000   \nmax                     1.000000  ...           1.000000          1.000000   \n\n       Age_(24.0, 31.0]  Age_(31.0, 40.4]  Age_(40.4, 80.0]  \\\ncount        887.000000        887.000000        887.000000   \nmean           0.214205          0.183766          0.200676   \nstd            0.410501          0.387511          0.400732   \nmin            0.000000          0.000000          0.000000   \n25%            0.000000          0.000000          0.000000   \n50%            0.000000          0.000000          0.000000   \n75%            0.000000          0.000000          0.000000   \nmax            1.000000          1.000000          1.000000   \n\n       Fare_(-0.001, 7.858]  Fare_(7.858, 10.5]  Fare_(10.5, 22.225]  \\\ncount            887.000000          887.000000           887.000000   \nmean               0.200676            0.205186             0.193912   \nstd                0.400732            0.404065             0.395584   \nmin                0.000000            0.000000             0.000000   \n25%                0.000000            0.000000             0.000000   \n50%                0.000000            0.000000             0.000000   \n75%                0.000000            0.000000             0.000000   \nmax                1.000000            1.000000             1.000000   \n\n       Fare_(22.225, 39.688]  Fare_(39.688, 512.329]  \ncount             887.000000              887.000000  \nmean                0.201804                0.198422  \nstd                 0.401573                0.399036  \nmin                 0.000000                0.000000  \n25%                 0.000000                0.000000  \n50%                 0.000000                0.000000  \n75%                 0.000000                0.000000  \nmax                 1.000000                1.000000  \n\n[8 rows x 31 columns]\n- - - - - - - - - - - - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "# Variable transform\n",
    "CATEGORICAL_FEATURES = ['Survived', 'Pclass', 'Sex', 'Siblings/Spouses Aboard', 'Parents/Children Aboard']\n",
    "NUMERICAL_FEATURES = ['Age', 'Fare']\n",
    "ALL_FEATURES = CATEGORICAL_FEATURES + NUMERICAL_FEATURES\n",
    "for feature_name in CATEGORICAL_FEATURES:\n",
    "    data = data.join(pd.get_dummies(data[feature_name], prefix=feature_name))\n",
    "    data.drop([feature_name], axis = 1, inplace=True)\n",
    "for feature_name in NUMERICAL_FEATURES:\n",
    "    data = data.join(pd.get_dummies(pd.qcut(data[feature_name], 5), prefix=feature_name))\n",
    "    data.drop([feature_name], axis = 1, inplace=True)\n",
    "features = list(data.columns)\n",
    "print('First, I divided these six features into two categories.')\n",
    "print('CATEGORICAL_FEATURES and NUMERICAL_FEATURES')\n",
    "print('For CATEGORICAL_FEATURES, I directly convert it to one-hot encoding.')\n",
    "print('For NUMERICAL_FEATURES, binning the data and then convert it to one-hot encoding.')\n",
    "print(data.describe())\n",
    "print('- - - - - - - - - - - - - - - - - - - -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy\n",
    "def Entropy(FEATURE):\n",
    "    ans = 0\n",
    "    for col in features:\n",
    "        if col[:len(FEATURE)] == FEATURE:\n",
    "            pr = data[col].sum()/data[col].count()\n",
    "            ans = ans - pr * math.log(pr)\n",
    "    return ans\n",
    "\n",
    "# Conditional Entropy\n",
    "def H(FEATURE1, FEATURE2):\n",
    "    ans = 0\n",
    "    for col_y in features:\n",
    "        if col_y[:len(FEATURE2)] == FEATURE2:\n",
    "            Pr_val = data[col_y].sum() / data[col_y].count()\n",
    "            sub_ans = 0\n",
    "            for col_x in features:\n",
    "                if col_x[:len(FEATURE1)] == FEATURE1:\n",
    "                    pr = np.sum(data[col_x]+data[col_y] == 2) / data[col_y].sum()\n",
    "                    if pr == 0:\n",
    "                        continue\n",
    "                    sub_ans = sub_ans - pr * math.log(pr)\n",
    "            ans = ans + Pr_val * sub_ans\n",
    "    return ans\n",
    "\n",
    "# Mutual Information\n",
    "def I(FEATURE1, FEATURE2):\n",
    "    return Entropy(FEATURE1) - H(FEATURE1, FEATURE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Max_Mutual_Information_feature\n",
    "def Find_Max_Mutual_Information_feature(DATA, ALL_FEATURES):\n",
    "    y_label = ALL_FEATURES[0]\n",
    "    Max_Mutual_Information_feature_name = ALL_FEATURES[1]\n",
    "    Max_Mutual_Information = I(Max_Mutual_Information_feature_name, y_label)\n",
    "    for feature_name in ALL_FEATURES[1:]:\n",
    "        if I(feature_name, y_label) > Max_Mutual_Information:\n",
    "            Max_Mutual_Information_feature_name = feature_name\n",
    "            Max_Mutual_Information = I(feature_name, y_label)\n",
    "    return Max_Mutual_Information_feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pclass\nPclass\n"
     ]
    }
   ],
   "source": [
    "# Split Data\n",
    "Selected_Feature = Find_Max_Mutual_Information_feature(data, ALL_FEATURES)\n",
    "New_ALL_FEATURES = [Feature for Feature in ALL_FEATURES if Feature != Selected_Feature]\n",
    "vals = [val for val in features if val[:len(Selected_Feature)] == Selected_Feature]\n",
    "for val in vals:\n",
    "    New_data = data[data[val] == 1].drop(vals, axis=1)\n",
    "    New_Selected_Feature = Find_Max_Mutual_Information_feature(New_data, New_ALL_FEATURES)\n",
    "    print(New_Selected_Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "        self.children = []\n",
    "        self.children_num = 0\n",
    "    def Insert(self, val, feature):\n",
    "        Child = Node(feature)\n",
    "        self.children.append(Child)\n",
    "        self.children_num = self.children_num + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Root = Node('sex')\n",
    "Root.Insert(0, 'Pclass')\n",
    "Root.Insert(3, 'Fare')\n",
    "Root.Insert(2, 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "Root.children_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}